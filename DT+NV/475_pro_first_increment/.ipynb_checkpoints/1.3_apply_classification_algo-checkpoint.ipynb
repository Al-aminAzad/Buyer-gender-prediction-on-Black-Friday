{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Wealth Index</th>\n",
       "      <th>Age at 1st Birth</th>\n",
       "      <th>Child Age</th>\n",
       "      <th>stunting</th>\n",
       "      <th>underweight</th>\n",
       "      <th>wasting</th>\n",
       "      <th>diar</th>\n",
       "      <th>fever</th>\n",
       "      <th>ari</th>\n",
       "      <th>Mother_BMI</th>\n",
       "      <th>wealth_index_cat</th>\n",
       "      <th>residence</th>\n",
       "      <th>sex</th>\n",
       "      <th>currently_working_mot</th>\n",
       "      <th>parents_edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorest</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.96</td>\n",
       "      <td>poor</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorest</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>poor</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorer</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.66</td>\n",
       "      <td>poor</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorer</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>poor</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barisal</td>\n",
       "      <td>middle</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.47</td>\n",
       "      <td>rich</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Division Wealth Index  Age at 1st Birth  Child Age  stunting  underweight  \\\n",
       "0  barisal      poorest                16         13         0            1   \n",
       "1  barisal      poorest                18         47         0            1   \n",
       "2  barisal       poorer                16         23         0            0   \n",
       "3  barisal       poorer                21         11         0            0   \n",
       "4  barisal       middle                15         51         1            1   \n",
       "\n",
       "   wasting  diar  fever  ari  Mother_BMI wealth_index_cat  residence     sex  \\\n",
       "0        1   0.0    0.0    1       20.96             poor          1  female   \n",
       "1        1   0.0    0.0    0       19.71             poor          1  female   \n",
       "2        0   0.0    0.0    0       20.66             poor          1  female   \n",
       "3        0   0.0    0.0    0       18.41             poor          1  female   \n",
       "4        0   0.0    0.0    0       19.47             rich          1  female   \n",
       "\n",
       "   currently_working_mot  parents_edu  \n",
       "0                    0.0          0.0  \n",
       "1                    0.0          0.0  \n",
       "2                    1.0          0.0  \n",
       "3                    0.0          0.0  \n",
       "4                    1.0          0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('modified_data_1.2.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding 'wealth_index_cat'\n",
    "#--------------------------------\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['wealth_index_cat'] = le.fit_transform(df['wealth_index_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Wealth Index</th>\n",
       "      <th>Age at 1st Birth</th>\n",
       "      <th>Child Age</th>\n",
       "      <th>stunting</th>\n",
       "      <th>underweight</th>\n",
       "      <th>wasting</th>\n",
       "      <th>diar</th>\n",
       "      <th>fever</th>\n",
       "      <th>ari</th>\n",
       "      <th>Mother_BMI</th>\n",
       "      <th>wealth_index_cat</th>\n",
       "      <th>residence</th>\n",
       "      <th>sex</th>\n",
       "      <th>currently_working_mot</th>\n",
       "      <th>parents_edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorest</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorest</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorer</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barisal</td>\n",
       "      <td>poorer</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>barisal</td>\n",
       "      <td>middle</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Division Wealth Index  Age at 1st Birth  Child Age  stunting  underweight  \\\n",
       "0  barisal      poorest                16         13         0            1   \n",
       "1  barisal      poorest                18         47         0            1   \n",
       "2  barisal       poorer                16         23         0            0   \n",
       "3  barisal       poorer                21         11         0            0   \n",
       "4  barisal       middle                15         51         1            1   \n",
       "\n",
       "   wasting  diar  fever  ari  Mother_BMI  wealth_index_cat  residence     sex  \\\n",
       "0        1   0.0    0.0    1       20.96                 0          1  female   \n",
       "1        1   0.0    0.0    0       19.71                 0          1  female   \n",
       "2        0   0.0    0.0    0       20.66                 0          1  female   \n",
       "3        0   0.0    0.0    0       18.41                 0          1  female   \n",
       "4        0   0.0    0.0    0       19.47                 1          1  female   \n",
       "\n",
       "   currently_working_mot  parents_edu  \n",
       "0                    0.0          0.0  \n",
       "1                    0.0          0.0  \n",
       "2                    1.0          0.0  \n",
       "3                    0.0          0.0  \n",
       "4                    1.0          0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df[['diar','fever','Mother_BMI','currently_working_mot','parents_edu']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6965 entries, 0 to 6964\n",
      "Data columns (total 16 columns):\n",
      "Division                 6965 non-null object\n",
      "Wealth Index             6965 non-null object\n",
      "Age at 1st Birth         6965 non-null int64\n",
      "Child Age                6965 non-null int64\n",
      "stunting                 6965 non-null int64\n",
      "underweight              6965 non-null int64\n",
      "wasting                  6965 non-null int64\n",
      "diar                     6965 non-null float64\n",
      "fever                    6965 non-null float64\n",
      "ari                      6965 non-null int64\n",
      "Mother_BMI               6965 non-null float64\n",
      "wealth_index_cat         6965 non-null int64\n",
      "residence                6965 non-null int64\n",
      "sex                      6965 non-null object\n",
      "currently_working_mot    6965 non-null float64\n",
      "parents_edu              6965 non-null float64\n",
      "dtypes: float64(5), int64(8), object(3)\n",
      "memory usage: 925.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age at 1st Birth</th>\n",
       "      <th>Child Age</th>\n",
       "      <th>stunting</th>\n",
       "      <th>underweight</th>\n",
       "      <th>wasting</th>\n",
       "      <th>diar</th>\n",
       "      <th>fever</th>\n",
       "      <th>ari</th>\n",
       "      <th>Mother_BMI</th>\n",
       "      <th>wealth_index_cat</th>\n",
       "      <th>residence</th>\n",
       "      <th>currently_working_mot</th>\n",
       "      <th>parents_edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "      <td>6965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.252692</td>\n",
       "      <td>29.563245</td>\n",
       "      <td>0.361091</td>\n",
       "      <td>0.321321</td>\n",
       "      <td>0.141709</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.449088</td>\n",
       "      <td>0.053984</td>\n",
       "      <td>21.694767</td>\n",
       "      <td>0.594831</td>\n",
       "      <td>0.685858</td>\n",
       "      <td>0.250862</td>\n",
       "      <td>0.300302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.297983</td>\n",
       "      <td>17.036364</td>\n",
       "      <td>0.480351</td>\n",
       "      <td>0.467017</td>\n",
       "      <td>0.348776</td>\n",
       "      <td>0.214589</td>\n",
       "      <td>0.497366</td>\n",
       "      <td>0.226003</td>\n",
       "      <td>4.575707</td>\n",
       "      <td>0.490960</td>\n",
       "      <td>0.464207</td>\n",
       "      <td>0.433509</td>\n",
       "      <td>0.458356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age at 1st Birth    Child Age     stunting  underweight      wasting  \\\n",
       "count       6965.000000  6965.000000  6965.000000  6965.000000  6965.000000   \n",
       "mean          18.252692    29.563245     0.361091     0.321321     0.141709   \n",
       "std            3.297983    17.036364     0.480351     0.467017     0.348776   \n",
       "min           12.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%           16.000000    14.000000     0.000000     0.000000     0.000000   \n",
       "50%           18.000000    30.000000     0.000000     0.000000     0.000000   \n",
       "75%           20.000000    45.000000     1.000000     1.000000     0.000000   \n",
       "max           46.000000    59.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              diar        fever          ari   Mother_BMI  wealth_index_cat  \\\n",
       "count  6965.000000  6965.000000  6965.000000  6965.000000       6965.000000   \n",
       "mean      0.048426     0.449088     0.053984    21.694767          0.594831   \n",
       "std       0.214589     0.497366     0.226003     4.575707          0.490960   \n",
       "min       0.000000     0.000000     0.000000    12.200000          0.000000   \n",
       "25%       0.000000     0.000000     0.000000    18.700000          0.000000   \n",
       "50%       0.000000     0.000000     0.000000    20.960000          1.000000   \n",
       "75%       0.000000     1.000000     0.000000    23.950000          1.000000   \n",
       "max       1.000000     1.000000     1.000000    99.980000          1.000000   \n",
       "\n",
       "         residence  currently_working_mot  parents_edu  \n",
       "count  6965.000000            6965.000000  6965.000000  \n",
       "mean      0.685858               0.250862     0.300302  \n",
       "std       0.464207               0.433509     0.458356  \n",
       "min       0.000000               0.000000     0.000000  \n",
       "25%       0.000000               0.000000     0.000000  \n",
       "50%       1.000000               0.000000     0.000000  \n",
       "75%       1.000000               1.000000     1.000000  \n",
       "max       1.000000               1.000000     1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:,[5,7,8,9,10,15]].values\n",
    "X = df.iloc[:,[5,7,8,9,10,15]].values\n",
    "\n",
    "Y = df.iloc[:,4].values\n",
    "Y_stun = df.iloc[:,4].values\n",
    "Y_underwei = df.iloc[:,5].values\n",
    "Y_wast = df.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_,x_test_,y_train_,y_test_ = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
    "x_train_stun,x_test_stun,y_train_stun,y_test_stun = train_test_split(X, Y_stun, test_size=0.2, random_state = 0)\n",
    "x_train_underwei,x_test_underwei,y_train_underwei,y_test_underwei = train_test_split(X, Y_underwei, test_size=0.2, random_state = 0)\n",
    "x_train_wast,x_test_wast,y_train_wast,y_test_wast = train_test_split(X, Y_wast, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling ( for a standard range )\n",
    "#-----------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train_ = sc.fit_transform(x_train_)\n",
    "x_train_stun = sc.fit_transform(x_train_stun)\n",
    "x_train_underwei = sc.fit_transform(x_train_underwei)\n",
    "x_train_wast = sc.fit_transform(x_train_wast)\n",
    "\n",
    "x_test_ = sc.transform(x_test_)\n",
    "x_test_stun = sc.transform(x_test_stun)\n",
    "x_test_underwei = sc.transform(x_test_underwei)\n",
    "x_test_wast = sc.transform(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca ( dimension reduction )\n",
    "# ---------------------------------\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components = 2)\n",
    "# x_train_stun = pca.fit_transform(x_train_stun)\n",
    "# x_train_underwei = pca.fit_transform(x_train_underwei)\n",
    "# x_train_wast = pca.fit_transform(x_train_wast)\n",
    "\n",
    "# x_test_stun = pca.transform(x_test_stun)\n",
    "# x_test_underwei = pca.transform(x_test_underwei)\n",
    "# x_test_wast = pca.transform(x_test_wast)\n",
    "\n",
    "# explain_vari = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decission tree classification\n",
    "# -------------------------------\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dClass = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "\n",
    "dClass.fit(x_train_stun,y_train_stun)\n",
    "dClass.fit(x_train_underwei,y_train_underwei)\n",
    "dClass.fit(x_train_wast,y_train_wast)\n",
    "\n",
    "y_pred_stun = dClass.predict(x_test_stun)\n",
    "y_pred_underwei = dClass.predict(x_test_underwei)\n",
    "y_pred_wast = dClass.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 68.629 % \n",
      "----------\n",
      "[[852  60]\n",
      " [377 104]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.93      0.80       912\n",
      "          1       0.63      0.22      0.32       481\n",
      "\n",
      "avg / total       0.67      0.69      0.63      1393\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 75.162 % \n",
      "----------\n",
      "[[912  29]\n",
      " [317 135]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.97      0.84       941\n",
      "          1       0.82      0.30      0.44       452\n",
      "\n",
      "avg / total       0.77      0.75      0.71      1393\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 80.402 % \n",
      "----------\n",
      "[[1073  117]\n",
      " [ 156   47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.90      0.89      1190\n",
      "          1       0.29      0.23      0.26       203\n",
      "\n",
      "avg / total       0.79      0.80      0.80      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_stun)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_stun))\n",
    "print(classification_report(y_test_stun,y_pred_stun))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_underwei,y_pred_underwei)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underwei,y_pred_underwei))\n",
    "print(classification_report(y_test_underwei,y_pred_underwei))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_wast)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_wast))\n",
    "print(classification_report(y_test_wast,y_pred_wast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naiveBayes classification\n",
    "#--------------------------\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "bayes = GaussianNB()\n",
    "bayes.fit(x_train_stun,y_train_stun)\n",
    "bayes.fit(x_train_underwei,y_train_underwei)\n",
    "bayes.fit(x_train_wast,y_train_wast)\n",
    "\n",
    "y_pred_bayes_stun = bayes.predict(x_test_stun)\n",
    "y_pred_bayes_under = bayes.predict(x_test_underwei)\n",
    "y_pred_bayes_wast = bayes.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 66.332 % \n",
      "----------\n",
      "[[904   8]\n",
      " [461  20]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.99      0.79       912\n",
      "          1       0.71      0.04      0.08       481\n",
      "\n",
      "avg / total       0.68      0.66      0.55      1393\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 69.562 % \n",
      "----------\n",
      "[[941   0]\n",
      " [424  28]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      1.00      0.82       941\n",
      "          1       1.00      0.06      0.12       452\n",
      "\n",
      "avg / total       0.79      0.70      0.59      1393\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 84.996 % \n",
      "----------\n",
      "[[1173   17]\n",
      " [ 192   11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92      1190\n",
      "          1       0.39      0.05      0.10       203\n",
      "\n",
      "avg / total       0.79      0.85      0.80      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_bayes_stun)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_bayes_stun))\n",
    "print(classification_report(y_test_stun,y_pred_bayes_stun))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_underwei,y_pred_bayes_under)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underwei,y_pred_bayes_under))\n",
    "print(classification_report(y_test_underwei,y_pred_bayes_under))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_bayes_wast)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_bayes_wast))\n",
    "print(classification_report(y_test_wast,y_pred_bayes_wast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomForest classification\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state = 0, criterion='entropy')\n",
    "forest.fit(x_train_stun,y_train_stun)\n",
    "forest.fit(x_train_underwei,y_train_underwei)\n",
    "forest.fit(x_train_wast,y_train_wast)\n",
    "\n",
    "y_pred_forest_stun = forest.predict(x_test_stun)\n",
    "y_pred_forest_under = forest.predict(x_test_underwei)\n",
    "y_pred_forest_wast = forest.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 69.131 % \n",
      "----------\n",
      "[[847  65]\n",
      " [365 116]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.93      0.80       912\n",
      "          1       0.64      0.24      0.35       481\n",
      "\n",
      "avg / total       0.68      0.69      0.64      1393\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 75.377 % \n",
      "----------\n",
      "[[905  36]\n",
      " [307 145]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.96      0.84       941\n",
      "          1       0.80      0.32      0.46       452\n",
      "\n",
      "avg / total       0.76      0.75      0.72      1393\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 80.474 % \n",
      "----------\n",
      "[[1065  125]\n",
      " [ 147   56]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.89      1190\n",
      "          1       0.31      0.28      0.29       203\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_forest_stun)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_forest_stun))\n",
    "print(classification_report(y_test_stun,y_pred_forest_stun))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_underwei,y_pred_forest_under)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underwei,y_pred_forest_under))\n",
    "print(classification_report(y_test_underwei,y_pred_forest_under))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_forest_wast)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_forest_wast))\n",
    "print(classification_report(y_test_wast,y_pred_forest_wast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "#--------------------------\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(random_state = 0)\n",
    "logReg.fit(x_train_stun,y_train_stun)\n",
    "logReg.fit(x_train_underwei,y_train_underwei)\n",
    "logReg.fit(x_train_wast,y_train_wast)\n",
    "\n",
    "y_pred_logReg_stun = logReg.predict(x_test_stun)\n",
    "y_pred_logReg_under = logReg.predict(x_test_underwei)\n",
    "y_pred_logReg_wast = logReg.predict(x_test_wast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of stunting:\n",
      "------------------\n",
      "\n",
      " 65.47 % \n",
      "----------\n",
      "[[912   0]\n",
      " [481   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79       912\n",
      "          1       0.00      0.00      0.00       481\n",
      "\n",
      "avg / total       0.43      0.65      0.52      1393\n",
      "\n",
      "\n",
      "\n",
      "result of underweight:\n",
      "-----------------\n",
      "\n",
      " 67.552 % \n",
      "----------\n",
      "[[941   0]\n",
      " [452   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      1.00      0.81       941\n",
      "          1       0.00      0.00      0.00       452\n",
      "\n",
      "avg / total       0.46      0.68      0.54      1393\n",
      "\n",
      "\n",
      "\n",
      "result of wasting:\n",
      "---------------------\n",
      "\n",
      " 85.427 % \n",
      "----------\n",
      "[[1190    0]\n",
      " [ 203    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92      1190\n",
      "          1       0.00      0.00      0.00       203\n",
      "\n",
      "avg / total       0.73      0.85      0.79      1393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('result of stunting:\\n------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_stun,y_pred_logReg_stun)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_stun,y_pred_logReg_stun))\n",
    "print(classification_report(y_test_stun,y_pred_logReg_stun))\n",
    "\n",
    "print('\\n\\nresult of underweight:\\n-----------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_underwei,y_pred_logReg_under)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_underwei,y_pred_logReg_under))\n",
    "print(classification_report(y_test_underwei,y_pred_logReg_under))\n",
    "\n",
    "print('\\n\\nresult of wasting:\\n---------------------')\n",
    "#---------------------------------\n",
    "\n",
    "print('\\n',round(accuracy_score(y_test_wast,y_pred_logReg_wast)*100,3),'%','\\n----------')\n",
    "print(confusion_matrix(y_test_wast,y_pred_logReg_wast))\n",
    "print(classification_report(y_test_wast,y_pred_logReg_wast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracy1 = pd.DataFrame({\n",
    "    'DecisionTreeClassifier': round(accuracy_score(y_test_stun,y_pred_stun)*100,3),\n",
    "    'naive Bayes':round(accuracy_score(y_test_stun,y_pred_bayes_stun)*100,3),\n",
    "    'random forest': round(accuracy_score(y_test_stun,y_pred_forest_stun)*100,3),\n",
    "    'logistic reg':round(accuracy_score(y_test_stun,y_pred_logReg_stun)*100,3)\n",
    "},index=['accuracy ( stunting ) %'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>naive Bayes</th>\n",
       "      <th>random forest</th>\n",
       "      <th>logistic reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy ( stunting ) %</th>\n",
       "      <td>68.629</td>\n",
       "      <td>66.332</td>\n",
       "      <td>69.131</td>\n",
       "      <td>65.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DecisionTreeClassifier  naive Bayes  random forest  \\\n",
       "accuracy ( stunting ) %                  68.629       66.332         69.131   \n",
       "\n",
       "                         logistic reg  \n",
       "accuracy ( stunting ) %         65.47  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAccuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracy2 = pd.DataFrame({\n",
    "    'DecisionTreeClassifier': round(accuracy_score(y_test_underwei,y_pred_underwei)*100,3),\n",
    "    'naive Bayes':round(accuracy_score(y_test_underwei,y_pred_bayes_under)*100,3),\n",
    "    'random forest': round(accuracy_score(y_test_underwei,y_pred_forest_under)*100,3),\n",
    "    'logistic reg':round(accuracy_score(y_test_underwei,y_pred_logReg_under)*100,3)\n",
    "},index=['accuracy ( underweight ) %'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>naive Bayes</th>\n",
       "      <th>random forest</th>\n",
       "      <th>logistic reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy ( underweight ) %</th>\n",
       "      <td>75.162</td>\n",
       "      <td>69.562</td>\n",
       "      <td>75.377</td>\n",
       "      <td>67.552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DecisionTreeClassifier  naive Bayes  \\\n",
       "accuracy ( underweight ) %                  75.162       69.562   \n",
       "\n",
       "                            random forest  logistic reg  \n",
       "accuracy ( underweight ) %         75.377        67.552  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAccuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAccuracy3 = pd.DataFrame({\n",
    "    'DecisionTreeClassifier': round(accuracy_score(y_test_wast,y_pred_wast)*100,3),\n",
    "    'naive Bayes':round(accuracy_score(y_test_wast,y_pred_bayes_wast)*100,3),\n",
    "    'random forest': round(accuracy_score(y_test_wast,y_pred_forest_wast)*100,3),\n",
    "    'logistic reg':round(accuracy_score(y_test_wast,y_pred_logReg_wast)*100,3)\n",
    "},index=['accuracy ( wasting ) %'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>naive Bayes</th>\n",
       "      <th>random forest</th>\n",
       "      <th>logistic reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy ( wasting ) %</th>\n",
       "      <td>80.402</td>\n",
       "      <td>84.996</td>\n",
       "      <td>80.474</td>\n",
       "      <td>85.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DecisionTreeClassifier  naive Bayes  random forest  \\\n",
       "accuracy ( wasting ) %                  80.402       84.996         80.474   \n",
       "\n",
       "                        logistic reg  \n",
       "accuracy ( wasting ) %        85.427  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAccuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# plt.scatter(x_train_stun[:,0],x_train_stun[:,1],c=y_train_stun,cmap='plasma')\n",
    "# plt.xlabel('pca1')\n",
    "# plt.ylabel('pca2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
